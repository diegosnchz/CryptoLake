:: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /root/.ivy2/cache
The jars for the packages stored in: /root/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-6c459018-ee58-4a03-b95a-9a98434ea579;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central
	found org.apache.kafka#kafka-clients;3.4.1 in central
	found org.lz4#lz4-java;1.8.0 in central
	found org.xerial.snappy#snappy-java;1.1.10.3 in central
	found org.slf4j#slf4j-api;2.0.7 in central
	found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
	found org.apache.hadoop#hadoop-client-api;3.3.4 in central
	found commons-logging#commons-logging;1.1.3 in central
	found com.google.code.findbugs#jsr305;3.0.0 in central
	found org.apache.commons#commons-pool2;2.11.1 in central
:: resolution report :: resolve 684ms :: artifacts dl 27ms
	:: modules in use:
	com.google.code.findbugs#jsr305;3.0.0 from central in [default]
	commons-logging#commons-logging;1.1.3 from central in [default]
	org.apache.commons#commons-pool2;2.11.1 from central in [default]
	org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
	org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
	org.apache.kafka#kafka-clients;3.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]
	org.lz4#lz4-java;1.8.0 from central in [default]
	org.slf4j#slf4j-api;2.0.7 from central in [default]
	org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-6c459018-ee58-4a03-b95a-9a98434ea579
	confs: [default]
	0 artifacts copied, 11 already retrieved (0kB/10ms)
26/02/11 17:43:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
26/02/11 17:43:54 INFO SparkContext: Running Spark version 3.5.0
26/02/11 17:43:54 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64
26/02/11 17:43:54 INFO SparkContext: Java version 11.0.20.1
26/02/11 17:43:54 INFO ResourceUtils: ==============================================================
26/02/11 17:43:54 INFO ResourceUtils: No custom resources configured for spark.driver.
26/02/11 17:43:54 INFO ResourceUtils: ==============================================================
26/02/11 17:43:54 INFO SparkContext: Submitted application: CryptoLake-StreamToBronze
26/02/11 17:43:54 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
26/02/11 17:43:54 INFO ResourceProfile: Limiting resource is cpu
26/02/11 17:43:54 INFO ResourceProfileManager: Added ResourceProfile id: 0
26/02/11 17:43:54 INFO SecurityManager: Changing view acls to: root
26/02/11 17:43:54 INFO SecurityManager: Changing modify acls to: root
26/02/11 17:43:54 INFO SecurityManager: Changing view acls groups to: 
26/02/11 17:43:54 INFO SecurityManager: Changing modify acls groups to: 
26/02/11 17:43:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
26/02/11 17:43:54 INFO Utils: Successfully started service 'sparkDriver' on port 34405.
26/02/11 17:43:54 INFO SparkEnv: Registering MapOutputTracker
26/02/11 17:43:54 INFO SparkEnv: Registering BlockManagerMaster
26/02/11 17:43:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
26/02/11 17:43:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
26/02/11 17:43:54 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
26/02/11 17:43:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4e1bad19-7cf0-4704-9565-0305c93a3938
26/02/11 17:43:54 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
26/02/11 17:43:54 INFO SparkEnv: Registering OutputCommitCoordinator
26/02/11 17:43:55 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
26/02/11 17:43:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
26/02/11 17:43:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://a0cf84f032ea:34405/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://a0cf84f032ea:34405/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at spark://a0cf84f032ea:34405/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://a0cf84f032ea:34405/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://a0cf84f032ea:34405/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://a0cf84f032ea:34405/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at spark://a0cf84f032ea:34405/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://a0cf84f032ea:34405/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://a0cf84f032ea:34405/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://a0cf84f032ea:34405/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://a0cf84f032ea:34405/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
26/02/11 17:43:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
26/02/11 17:43:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.kafka_kafka-clients-3.4.1.jar
26/02/11 17:43:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Copying /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/com.google.code.findbugs_jsr305-3.0.0.jar
26/02/11 17:43:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.commons_commons-pool2-2.11.1.jar
26/02/11 17:43:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
26/02/11 17:43:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Copying /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.lz4_lz4-java-1.8.0.jar
26/02/11 17:43:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Copying /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.xerial.snappy_snappy-java-1.1.10.3.jar
26/02/11 17:43:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Copying /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.slf4j_slf4j-api-2.0.7.jar
26/02/11 17:43:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.hadoop_hadoop-client-api-3.3.4.jar
26/02/11 17:43:55 INFO SparkContext: Added file file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Copying /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/commons-logging_commons-logging-1.1.3.jar
26/02/11 17:43:55 INFO Executor: Starting executor ID driver on host a0cf84f032ea
26/02/11 17:43:55 INFO Executor: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64
26/02/11 17:43:55 INFO Executor: Java version 11.0.20.1
26/02/11 17:43:55 INFO Executor: Starting executor with user classpath (userClassPathFirst = true): ''
26/02/11 17:43:55 INFO Executor: Created or updated repl class loader org.apache.spark.util.ChildFirstURLClassLoader@2527fea5 for default.
26/02/11 17:43:55 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
26/02/11 17:43:55 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.hadoop_hadoop-client-api-3.3.4.jar
26/02/11 17:43:55 INFO Executor: Fetching file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/com.google.code.findbugs_jsr305-3.0.0.jar
26/02/11 17:43:55 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
26/02/11 17:43:55 INFO Executor: Fetching file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.xerial.snappy_snappy-java-1.1.10.3.jar
26/02/11 17:43:55 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
26/02/11 17:43:55 INFO Executor: Fetching file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.slf4j_slf4j-api-2.0.7.jar
26/02/11 17:43:55 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.commons_commons-pool2-2.11.1.jar
26/02/11 17:43:55 INFO Executor: Fetching file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/commons-logging_commons-logging-1.1.3.jar
26/02/11 17:43:55 INFO Executor: Fetching file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.lz4_lz4-java-1.8.0.jar
26/02/11 17:43:55 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.kafka_kafka-clients-3.4.1.jar
26/02/11 17:43:55 INFO Executor: Fetching spark://a0cf84f032ea:34405/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO TransportClientFactory: Successfully created connection to a0cf84f032ea/172.22.0.3:34405 after 40 ms (0 ms spent in bootstraps)
26/02/11 17:43:55 INFO Utils: Fetching spark://a0cf84f032ea:34405/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp9521262583469686602.tmp
26/02/11 17:43:55 INFO Utils: /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp9521262583469686602.tmp has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
26/02/11 17:43:55 INFO Executor: Adding file:/tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to class loader default
26/02/11 17:43:55 INFO Executor: Fetching spark://a0cf84f032ea:34405/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Fetching spark://a0cf84f032ea:34405/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp15187896293080969966.tmp
26/02/11 17:43:55 INFO Utils: /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp15187896293080969966.tmp has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.slf4j_slf4j-api-2.0.7.jar
26/02/11 17:43:55 INFO Executor: Adding file:/tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.slf4j_slf4j-api-2.0.7.jar to class loader default
26/02/11 17:43:55 INFO Executor: Fetching spark://a0cf84f032ea:34405/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Fetching spark://a0cf84f032ea:34405/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp430935634758779421.tmp
26/02/11 17:43:55 INFO Utils: /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp430935634758779421.tmp has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
26/02/11 17:43:55 INFO Executor: Adding file:/tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to class loader default
26/02/11 17:43:55 INFO Executor: Fetching spark://a0cf84f032ea:34405/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Fetching spark://a0cf84f032ea:34405/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp13038513388550070003.tmp
26/02/11 17:43:55 INFO Utils: /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp13038513388550070003.tmp has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/com.google.code.findbugs_jsr305-3.0.0.jar
26/02/11 17:43:55 INFO Executor: Adding file:/tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/com.google.code.findbugs_jsr305-3.0.0.jar to class loader default
26/02/11 17:43:55 INFO Executor: Fetching spark://a0cf84f032ea:34405/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1770831834049
26/02/11 17:43:55 INFO Utils: Fetching spark://a0cf84f032ea:34405/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp11423699835998247792.tmp
26/02/11 17:43:55 INFO Utils: /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp11423699835998247792.tmp has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
26/02/11 17:43:56 INFO Executor: Adding file:/tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to class loader default
26/02/11 17:43:56 INFO Executor: Fetching spark://a0cf84f032ea:34405/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1770831834049
26/02/11 17:43:56 INFO Utils: Fetching spark://a0cf84f032ea:34405/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp14334551504962626364.tmp
26/02/11 17:43:56 INFO Utils: /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp14334551504962626364.tmp has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.commons_commons-pool2-2.11.1.jar
26/02/11 17:43:56 INFO Executor: Adding file:/tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.commons_commons-pool2-2.11.1.jar to class loader default
26/02/11 17:43:56 INFO Executor: Fetching spark://a0cf84f032ea:34405/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1770831834049
26/02/11 17:43:56 INFO Utils: Fetching spark://a0cf84f032ea:34405/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp6780590284129551179.tmp
26/02/11 17:43:56 INFO Utils: /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp6780590284129551179.tmp has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.lz4_lz4-java-1.8.0.jar
26/02/11 17:43:56 INFO Executor: Adding file:/tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.lz4_lz4-java-1.8.0.jar to class loader default
26/02/11 17:43:56 INFO Executor: Fetching spark://a0cf84f032ea:34405/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1770831834049
26/02/11 17:43:56 INFO Utils: Fetching spark://a0cf84f032ea:34405/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp12808476650317278121.tmp
26/02/11 17:43:56 INFO Utils: /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp12808476650317278121.tmp has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.xerial.snappy_snappy-java-1.1.10.3.jar
26/02/11 17:43:56 INFO Executor: Adding file:/tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.xerial.snappy_snappy-java-1.1.10.3.jar to class loader default
26/02/11 17:43:56 INFO Executor: Fetching spark://a0cf84f032ea:34405/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1770831834049
26/02/11 17:43:56 INFO Utils: Fetching spark://a0cf84f032ea:34405/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp16354125273261106704.tmp
26/02/11 17:43:56 INFO Utils: /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp16354125273261106704.tmp has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/commons-logging_commons-logging-1.1.3.jar
26/02/11 17:43:56 INFO Executor: Adding file:/tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/commons-logging_commons-logging-1.1.3.jar to class loader default
26/02/11 17:43:56 INFO Executor: Fetching spark://a0cf84f032ea:34405/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1770831834049
26/02/11 17:43:56 INFO Utils: Fetching spark://a0cf84f032ea:34405/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp8285661968394003295.tmp
26/02/11 17:43:56 INFO Utils: /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp8285661968394003295.tmp has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.kafka_kafka-clients-3.4.1.jar
26/02/11 17:43:56 INFO Executor: Adding file:/tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.kafka_kafka-clients-3.4.1.jar to class loader default
26/02/11 17:43:56 INFO Executor: Fetching spark://a0cf84f032ea:34405/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1770831834049
26/02/11 17:43:56 INFO Utils: Fetching spark://a0cf84f032ea:34405/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp6591054652621707030.tmp
26/02/11 17:43:56 INFO Utils: /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/fetchFileTemp6591054652621707030.tmp has been previously copied to /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.hadoop_hadoop-client-api-3.3.4.jar
26/02/11 17:43:56 INFO Executor: Adding file:/tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/userFiles-95e51e39-435b-4592-940f-301f335f8f72/org.apache.hadoop_hadoop-client-api-3.3.4.jar to class loader default
26/02/11 17:43:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34851.
26/02/11 17:43:56 INFO NettyBlockTransferService: Server created on a0cf84f032ea:34851
26/02/11 17:43:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
26/02/11 17:43:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, a0cf84f032ea, 34851, None)
26/02/11 17:43:56 INFO BlockManagerMasterEndpoint: Registering block manager a0cf84f032ea:34851 with 434.4 MiB RAM, BlockManagerId(driver, a0cf84f032ea, 34851, None)
26/02/11 17:43:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, a0cf84f032ea, 34851, None)
26/02/11 17:43:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, a0cf84f032ea, 34851, None)
INFO:__main__:Spark Session Created
26/02/11 17:43:56 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
26/02/11 17:43:56 INFO SharedState: Warehouse path is 'file:/opt/spark/work-dir/spark-warehouse'.
Traceback (most recent call last):
  File "/opt/spark/work-dir/src/processing/streaming/stream_to_bronze.py", line 61, in <module>
    main()
  File "/opt/spark/work-dir/src/processing/streaming/stream_to_bronze.py", line 47, in main
    spark.sql("CREATE DATABASE IF NOT EXISTS cryptolake.bronze")
  File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/session.py", line 1631, in sql
  File "/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
  File "/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 179, in deco
  File "/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py", line 326, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o48.sql.
: java.lang.LinkageError: loader constraint violation: loader org.apache.spark.util.ChildFirstURLClassLoader @59072e9d wants to load interface org.slf4j.Logger. A different interface with the same name was previously loaded by 'app'. (org.slf4j.Logger is in unnamed module of loader 'app')
	at java.base/java.lang.ClassLoader.defineClass1(Native Method)
	at java.base/java.lang.ClassLoader.defineClass(Unknown Source)
	at java.base/java.security.SecureClassLoader.defineClass(Unknown Source)
	at java.base/java.net.URLClassLoader.defineClass(Unknown Source)
	at java.base/java.net.URLClassLoader$1.run(Unknown Source)
	at java.base/java.net.URLClassLoader$1.run(Unknown Source)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/java.net.URLClassLoader.findClass(Unknown Source)
	at java.base/java.lang.ClassLoader.loadClass(Unknown Source)
	at org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:55)
	at java.base/java.lang.ClassLoader.loadClass(Unknown Source)
	at org.slf4j.helpers.SubstituteServiceProvider.<init>(SubstituteServiceProvider.java:9)
	at org.slf4j.LoggerFactory.<clinit>(LoggerFactory.java:95)
	at org.apache.hadoop.conf.Configuration.<clinit>(Configuration.java:229)
	at java.base/java.lang.Class.forName0(Native Method)
	at java.base/java.lang.Class.forName(Unknown Source)
	at org.apache.hadoop.conf.Configuration.getClassByNameOrNull(Configuration.java:2625)
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:98)
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:81)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467)
	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)
	at org.apache.iceberg.hadoop.Util.getFs(Util.java:56)
	at org.apache.iceberg.hadoop.HadoopCatalog.initialize(HadoopCatalog.java:112)
	at org.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:239)
	at org.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:284)
	at org.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:143)
	at org.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:555)
	at org.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)
	at org.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:53)
	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)
	at org.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:53)
	at org.apache.spark.sql.connector.catalog.LookupCatalog$CatalogAndNamespace$.unapply(LookupCatalog.scala:86)
	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:51)
	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:30)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$4(AnalysisHelper.scala:175)
	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)
	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)
	at org.apache.spark.sql.catalyst.plans.logical.CreateNamespace.mapChildren(v2Commands.scala:548)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:175)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators(AnalysisHelper.scala:76)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators$(AnalysisHelper.scala:75)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:30)
	at org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:27)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)
	at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
	at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
	at scala.collection.immutable.List.foldLeft(List.scala:91)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)
	at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)
	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)
	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)
	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)
	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)
	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.base/java.lang.reflect.Method.invoke(Unknown Source)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Unknown Source)

26/02/11 17:44:00 INFO SparkContext: Invoking stop() from shutdown hook
26/02/11 17:44:00 INFO SparkContext: SparkContext is stopping with exitCode 0.
26/02/11 17:44:00 INFO SparkUI: Stopped Spark web UI at http://a0cf84f032ea:4040
26/02/11 17:44:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
26/02/11 17:44:00 INFO MemoryStore: MemoryStore cleared
26/02/11 17:44:00 INFO BlockManager: BlockManager stopped
26/02/11 17:44:00 INFO BlockManagerMaster: BlockManagerMaster stopped
26/02/11 17:44:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
26/02/11 17:44:00 INFO SparkContext: Successfully stopped SparkContext
26/02/11 17:44:00 INFO ShutdownHookManager: Shutdown hook called
26/02/11 17:44:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c
26/02/11 17:44:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-e52c5f01-f0e1-46d8-ac90-76314b3cb173
26/02/11 17:44:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-e53b4d7a-6466-4eb7-91ac-26cd60ce9b6c/pyspark-24c09295-62b7-40fe-8421-7a466d23a9ee
